% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Related Work}\label{chapter:relatedwork}
\section{Attack Vectors}
Working with sensitive data brings out multiple risks that have to be assessed before actions can be taken. We compile possible attack vectors and how they have been solved in other systems.

\subsection{Centralized}
To improve efficiency, centralized information systems have always been a go-to infrastructure. The advantages of simple deployment, ease of maintenance and less bureaucracy will always be an incentive for big companies and governments to consider it. In 1965, the US Social Science Research Council proposed a National Data Center for the purpose of storing all data in a central location for statistical data analysis. In the end, the plans for the system were shot down because of the lack of privacy protection.
% Todo: \cite[Centralized Information Systems and the Legal Right to Privacy.pdf]

Today, there are several big tech companies, that are collecting information about their users and storing them in central databases. But centralization has a fatal flaw for protecting privacy. The collection of sensitive data in one location pose a high risk to their originator. Centralized databases that store private information are one of the weak points that have been on constant attack. In 2019, there have been over 5000 data breaches with almost 8 billion records exposed in the first three quarters, 33\% more compared to the number reported in the first nine months of 2018. Around 10\% of the breaches originated from the inside, from accidental leaks to malicious publications.
% Todo: \cite[https://www.helpnetsecurity.com/2019/11/14/breaches-2019/]

\subsection{Inference}
If we strip away all sensitive information, there remains a risk of private data leaking by re-identification, reconstruction and tracing. The most harmful problem is the danger of re-identification. This attack enables malicious actors to deduce identity information using other publicly available data sets or auxiliary knowledge. L. Sweeney was able to re-identify former Massachusetts governor William Weld by linking medical records from the Group Insurance Commission and the voter registration list.
% Todo: \cite[k-Anonymity/ A Model for Protecting Privacy]
% Todo: \cite[Exposed! A Survey of Attacks on Private Data.pdf]
 The goal of reconstruction is to determine sensitive data from a data set using publicly available information. 
 % Todo: \cite[Exposed! A Survey of Attacks on Private Data.pdf]
Tracing on the other hand is the ability to identify if an individual is present in a data set or not.
% Todo: \cite[Exposed! A Survey of Attacks on Private Data.pdf]
% Todo: \cite[Resolving Individuals Contributing Trace Amounts of DNA to Highly Complex Mixtures Using High-Density SNP Genotyping Microarrays]

\subsection{Location Tracking}
In regards to location data, the ability to infer the home and work location pose both risks for privacy and life and limb. Research has shown that it is possible to deduce the home address of an individual and even his work place using historical location data.
% Todo: \cite[Inference Attacks on Location Tracks]
% Todo: \cite[Please Forget Where I Was Last Summer: The Privacy Risks of Public Location (Meta)Data]
% Todo: \cite[On the Anonymity of Home/Work Location Pairs]
% Todo: \cite[Inference Attacks on Location Tracks]
 Being able to analyze the movement pattern and predict the presence of a person in a certain location may put his or her life in danger. 

\section{Countermeasures}
To implement a secure platform that is not so vulnerable to the problems proposed in the sections above, we look into methods and design decisions to prevent them.
\subsection{Distributed and Decentralized}
The dangers of data breaches originate from outside the companies as well as inside and their cause range from poorly implemented security to lax security policies to human error. 
% Todo: \cite[https://www.helpnetsecurity.com/2019/11/14/breaches-2019/]
Figure [X] depicts two more alternatives in place of a centralized architecture: distributed and decentralized.
% Todo: Insert figure

When the internet was implemented as Advanced Research Projects Agency Network (ARPANET) in 1969, it was a decentralized network of computers scattered across the United States. With the adoption of the TCP/IP in 1982, it became the internet, an interconnected network of networks.
% Todo: \cite[TCP/IP Network Administration, 3rd Edition]
In 1989, Tim Berners-Lee introduced the world wide web as a read-only means of accessing information from other computers and the commercialization turned it into the centralized web we know today. 

In the last decade, we have seen a rise in attempts to reorganize the internet. This trend amassed attention in 2009, when the creator under the pseudonym Satoshi Nakamoto created Bitcoin, "A Peer-to-Peer Electronic Cash System" leveraging blockchain technology, followed by the Ethereum platform in 2013.
% Todo: \cite[Bitcoin whitepaper]
% Todo: \cite[Ethereum whitepaper]
% Todo: Write more about decentralization and distributed

The goal of decentralization is the separation of power from a single instance, here for instance is to take away the control over data from monopolies. 

Distribution takes decentralization a step further, by eliminating the central control. All instances have the same power. 

One of the protocols that arose from this niche is the InterPlanetary File System (IPFS). IPFS is a peer-to-peer hypermedia protocol to make the web more decentralized and distributed.
% Todo: \cite[IPFS whitepaper]

Using distributed storage removes the single point of vulnerability and lowers the the effort-to-reward balance and thus might deter malicious actors to try to steal data.

\subsection{Homomorphic encryption}
Another way to ensure that anonymity is provided, is when the data is not readable. If a malicious actor manages to steal private data while it is still encrypted, he won't be able to infer identity or additional information, unless he manages to decrypt it beforehand. This protects that intermediate parties can't use data mining to infringe on sensitive data.

Homomorphic encryption enables the arithmetic operations on an encrypted data set. They are separated into three categories:
\begin{itemize}
	\item \textbf{Fully Homomorphic Encryption (FHE)} allow multiple arbitrary operations, but have a lot of overhead and thus are expensive computationally.
	\item \textbf{Somewhat Homomorphic Encryption (SWHE)} support only selected operations to a limited number of times and are computationally more feasible.
	\item \textbf{Partially Homomorphic Encryption (PHE)} enables one type of operation any number of times.
\end{itemize}
% Todo: \cite[A Review of Homomorphic Encryption Libraries for Secure Computation]
% Todo: Write more about homomorphic encryption

\subsection{Differential privacy}
Differential privacy can be used to prevent statistical databases from leaking private information. An algorithm is differential private when it disables tracing attacks, meaning that an output doesn't show signs if a particular individual is present in it or not. 
% Todo: Write more about differential privacy

\subsection{k-Anonymity}
The above sections have shown, that if a data set seems anonymous by itself, quasi-identifiers, such as ZIP code, birth date or sex, still enable a malicious actor to link an individual to his data. One of the countermeasures to this problem, is providing k-anonymity. This is achieved when every query for a quasi-identifier returns at least k results. A quasi-identifier is an identifier or a combination of non-identifying attributes, that can used to link with external data sources to create new identifiers. For this, P. Samarati and L. Sweeney suggest the use of generalization and suppression.
% Todo: \cite[k-Anonymity/ A Model for Protecting Privacy.pdf]
% Todo: \cite[Protecting Privacy when Disclosing Information/ k-Anonymity and Its Enforcement through Generalization and Suppression.pdf]
Former is realized by expanding certain attributes into ranges. For instance instead of assigning the real age, an age range is used. This results in a loss of accuracy, but higher degree of anonymity and thus privacy. For the latter, there are two methods of suppression. Attribute suppression removes attributes from the data set, reducing the number of possible quasi-identifiers by lowering the number of possible combinations. Record suppression on the other hand deletes entire entries in the data set to take out unique entries that don't meet the criteria of k-anonymity.
% Todo: \cite[Guide to Basic Data Anonymisation Techniques.pdf]
\subsection{Spatial Cloaking}
% Todo: Write about spatial cloaking
